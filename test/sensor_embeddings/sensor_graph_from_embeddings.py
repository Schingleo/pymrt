"""This experiment iterates the hyper parameters for skip-gram models to
evaluate how well the sensor embedding learned through the skip-gram model
fits the layout of the sensors on the smart home floor plan.

During the learning of this sensor embedding model, a k-skip-2-gram model using
noise-contrastive estimation is implemented. The hyper-parameters of this model
includes the size of window to learn co-occurrence from, the number of
positive samples to be drawn from each window and the number of negative
samples used in the NCE process.

The sensor graph is generated by comparing the distance between every two
sensors to a threshold. If the distance between two sensors is smaller than
the threshold, these two sensors are considered adjacent. The threshold is
chosen to be the smallest value such that all sensors are connected.
"""

import os
import logging
import pickle
import numpy as np
from pymrt.casas import CASASDataset
from pymrt.ml.sensor2vec import sensor2vec
from pymrt.tracking.utils import euclidean_distance_matrix
from pymrt.visualizer import plot_sensor_graph_with_embeddings


dataset_dir = r"""../../data/datasets/tm004_161219_9d"""
site_dir = r"""../../data/sites/tm004"""


def config_debug():
    """Configure stderr debugger options
    """
    os.makedirs('./log', exist_ok=True)
    logging.basicConfig(
        level=logging.DEBUG,
        format='[%(asctime)s] %(name)s:%(levelname)s:%(message)s',
        handlers=[logging.StreamHandler(),
                  logging.FileHandler(os.path.join('log',
                                                   'tm004_step_mrt.log'))]
    )


# Check point
chkpt_dir = './result/'

# Hyper parameters
bs = 128
nn = 1
sw = 3
ns = 4


def load_dataset():
    """Load CASAS smart home dataset from folder"""
    dataset = CASASDataset(directory=dataset_dir, site_dir=site_dir)
    dataset_chkpt_file = os.path.join(chkpt_dir,
                                      dataset.data_dict['name'] + ".pkl")
    if os.path.exists(dataset_chkpt_file):
        dataset = CASASDataset.load(dataset_chkpt_file)
    else:
        dataset.load_events(show_progress=True)
        dataset.save(dataset_chkpt_file)
    dataset.summary()
    return dataset


def get_sequence(dataset):
    """Translate sensor events in the dataset into sensor sequence"""
    sequence_chkpt_file = os.path.join(
        chkpt_dir,
        dataset.data_dict['name'] + "_sequence.pkl"
    )
    if os.path.exists(sequence_chkpt_file):
        fp = open(sequence_chkpt_file, "rb")
        sensor_seq, time_seq = pickle.load(fp)
        fp.close()
    else:
        sensor_seq, time_seq = dataset.to_sensor_sequence()
        fp = open(sequence_chkpt_file, "wb")
        pickle.dump((sensor_seq, time_seq), fp, protocol=-1)
        fp.close()
    return sensor_seq, time_seq


def get_sensor_embedding(dataset, sensor_seq):
    chkpt_filename = dataset.data_dict['name'] + \
                     "_embedding_nn_%d_sw_%d_ns_%d.pkl" % (
                         nn, sw, ns
                     )
    embedding_chkpt_file = os.path.join(
        chkpt_dir,
        chkpt_filename
    )
    if os.path.exists(embedding_chkpt_file):
        fp = open(embedding_chkpt_file, 'rb')
        embeddings, distance_matrix = pickle.load(fp)
        fp.close()
    else:
        embeddings, _ = sensor2vec(
            len(dataset.sensor_list), sensor_seq,
            embedding_size=3, skip_window=sw, num_skips=ns,
            batch_size=bs, num_neg_samples=nn*bs,
            learning_rate=0.05, num_steps=100000)
        distance_matrix = euclidean_distance_matrix(
            embeddings=embeddings
        )
        fp = open(embedding_chkpt_file, 'wb+')
        pickle.dump((embeddings, distance_matrix), fp)
        fp.close()
    return embeddings, distance_matrix


def is_fully_connected(adjancency_matrix):
    connected_indices = [0]
    i = 0
    while i < len(connected_indices):
        for j in range(adjancency_matrix.shape[1]):
            if adjancency_matrix[connected_indices[i], j] and \
                    j not in connected_indices:
                connected_indices.append(j)
        i += 1
    return len(connected_indices) == adjancency_matrix.shape[0]


def get_adjancy_matrix(distance_matrix):
    """Increase threshold for euclidean distance until the graph is fully
    connected.
    """
    threshold_list = np.sort(distance_matrix.flatten())
    for threshold in threshold_list:
        adjancency_matrix = distance_matrix <= threshold
        if is_fully_connected(adjancency_matrix):
            return adjancency_matrix, threshold


if __name__ == "__main__":
    config_debug()
    os.makedirs(chkpt_dir, exist_ok=True)
    dataset = load_dataset()
    sensor_seq, sensor_time_seq = get_sequence(dataset)

    sw_list = np.array([3, 5, 7, 9, 11, 13, 15, 17], dtype=np.int)
    ns_list = 2 * (sw_list - 1)
    bs_list = 64 * ns_list
    nn = 1

    for i in range(sw_list.shape[0]):
        sw = int(sw_list[i])
        ns = int(ns_list[i])
        bs = int(bs_list[i])
        embeddings, distance_matrix = get_sensor_embedding(
            dataset, sensor_seq
        )
        adjancency_matrix, threshold = get_adjancy_matrix(
            distance_matrix=distance_matrix
        )
        print(threshold)
        plot_sensor_graph_with_embeddings(
            dataset=dataset, embeddings=embeddings,
            threshold=threshold, distance='euclidean',
            filename=os.path.join(
                chkpt_dir,
                dataset.data_dict['name'] +
                "_sensor_graph_nn_%d_sw_%d_ns_%d.pdf" % (
                    nn, sw, ns
                )
            )
        )
